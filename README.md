# AI Job Market Analysis

A comprehensive data science project analyzing the AI job market using machine learning techniques for salary prediction, job classification, and market segmentation.

## ğŸ¯ Project Overview

This project analyzes AI job market data to provide insights into:
- **Salary Prediction**: Predict salaries based on job characteristics
- **Job Classification**: Categorize jobs by experience level, company size, etc.
- **Market Segmentation**: Identify distinct job market clusters
- **Trend Analysis**: Understand market dynamics and patterns

## ğŸ“Š Dataset

**Source**: Kaggle AI Job Market Dataset  
**Size**: 15,000 job postings  
**Features**: 19 columns including salary, experience, location, company details, and job requirements

### Key Columns
- `salary_usd`: Annual salary in USD (target for regression)
- `experience_level`: EN (Entry), MI (Mid), SE (Senior), EX (Executive)
- `employment_type`: FT, PT, CT, FL
- `company_size`: S (Small), M (Medium), L (Large)
- `remote_ratio`: 0, 50, 100 (percentage remote work)
- `job_title`, `company_location`, `employee_residence`

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ src/                    # Source code (modular architecture)
â”‚   â”œâ”€â”€ data/              # Data processing modules
â”‚   â”‚   â”œâ”€â”€ loader.py      # Database operations and data loading
â”‚   â”‚   â””â”€â”€ cleaner.py     # Data cleaning and preprocessing
â”‚   â”œâ”€â”€ analysis/          # Analysis modules
â”‚   â”‚   â”œâ”€â”€ eda.py         # Exploratory data analysis
â”‚   â”‚   â”œâ”€â”€ outliers.py    # Outlier detection and analysis
â”‚   â”‚   â””â”€â”€ cleaning.py    # Advanced data cleaning
â”‚   â”œâ”€â”€ models/            # Machine learning modules
â”‚   â”‚   â”œâ”€â”€ regression.py  # Salary prediction models
â”‚   â”‚   â”œâ”€â”€ classification.py # Job classification models
â”‚   â”‚   â””â”€â”€ clustering.py  # Market segmentation models
â”‚   â””â”€â”€ utils/             # Utility modules
â”‚       â”œâ”€â”€ config.py      # Configuration management
â”‚       â””â”€â”€ helpers.py     # Helper functions
â”œâ”€â”€ scripts/               # Pipeline scripts
â”‚   â”œâ”€â”€ run_pipeline.py    # Complete data pipeline
â”‚   â”œâ”€â”€ run_analysis.py    # Analysis pipeline
â”‚   â””â”€â”€ run_modeling.py    # Modeling pipeline
â”œâ”€â”€ config/                # Configuration files
â”‚   â””â”€â”€ config.yaml        # Main configuration
â”œâ”€â”€ outputs/               # Generated outputs
â”‚   â”œâ”€â”€ plots/            # Visualizations
â”‚   â”œâ”€â”€ models/           # Trained models
â”‚   â””â”€â”€ reports/          # Analysis reports
â”œâ”€â”€ data/                  # Data files
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ run_modeling.py        # Main launcher script
â””â”€â”€ main.py               # CLI entry point
```

## âœ¨ Features

### ğŸ”„ Modular Architecture
- **Clean separation** of data processing, analysis, and modeling
- **Reusable components** with consistent interfaces
- **Configuration-driven** with YAML config and environment variables
- **Comprehensive error handling** and logging

### ğŸ“ˆ Advanced Analytics
- **Exploratory Data Analysis**: Distribution analysis, correlation matrices, trend visualization
- **Outlier Detection**: Statistical and ML-based outlier identification
- **Data Quality Assessment**: Missing values, duplicates, data type validation

### ğŸ¤– Machine Learning Pipeline
- **Regression**: Salary prediction using Multiple algorithms (Linear, Ridge, Lasso, Random Forest, Gradient Boosting)
- **Classification**: Job categorization with high accuracy (99%+ accuracy achieved)
- **Clustering**: Market segmentation using K-Means, DBSCAN, Agglomerative, Gaussian Mixture

### ğŸ“Š Comprehensive Reporting
- **Automated visualizations** with professional plots
- **Detailed reports** for each analysis phase
- **Model performance metrics** and comparisons
- **Business insights** and recommendations

## ğŸš€ Quick Start

### 1. Setup Environment
```bash
# Install dependencies
pip install -r requirements.txt

# Set up database credentials (optional)
cp .env.template .env
# Edit .env with your database credentials
```

### 2. Run Complete Analysis
```bash
# Run everything (recommended for first-time users)
python run_modeling.py --all

# Or run specific components
python run_modeling.py --regression
python run_modeling.py --classification  
python run_modeling.py --clustering
```

### 3. Explore Results
- **Plots**: `outputs/plots/` - Visualizations and charts
- **Models**: `outputs/models/` - Trained ML models (.joblib files)
- **Reports**: `outputs/reports/` - Detailed analysis reports

## ğŸ“‹ Pipeline Scripts

### Data Pipeline
```bash
python scripts/run_pipeline.py    # Complete data processing
```

### Analysis Pipeline  
```bash
python scripts/run_analysis.py    # EDA, outliers, cleaning
```

### Modeling Pipeline
```bash
python scripts/run_modeling.py    # ML models and predictions
```

## ğŸ“ˆ Results Summary

### ğŸ¯ Model Performance
- **Salary Prediction**: RÂ² = 0.66 (Gradient Boosting)
- **Job Classification**: 100% Accuracy (Random Forest)
- **Market Segmentation**: 2 optimal clusters identified

### ğŸ’¡ Key Insights
1. **Experience level** is the strongest predictor of salary
2. **Remote work ratio** significantly impacts compensation
3. **Company size** correlates with salary ranges
4. **Geographic location** affects market dynamics
5. **Job market** segments into distinct clusters with different characteristics

## ğŸ› ï¸ Technologies Used

- **Python 3.8+**
- **Data Science**: pandas, numpy, scipy
- **Machine Learning**: scikit-learn  
- **Visualization**: matplotlib, seaborn
- **Database**: SQLite
- **Configuration**: PyYAML, python-dotenv
- **Testing**: pytest

## ğŸ“ Key Files

- `run_modeling.py` - Main launcher script
- `src/models/regression.py` - Salary prediction models
- `src/models/classification.py` - Job classification models  
- `src/models/clustering.py` - Market segmentation models
- `config/config.yaml` - Configuration settings
- `requirements.txt` - Python dependencies

## ğŸ“ Usage Examples

### Custom Target Classification
```bash
python run_modeling.py --classification --target-column company_size
```

### Specific Cluster Count
```bash
python run_modeling.py --clustering --n-clusters 5
```

### Individual Model Training
```bash
python -c "from src.models.regression import run_salary_prediction; run_salary_prediction()"
```

## ğŸ” What's Generated

After running the pipeline, you'll have:

### ğŸ“Š Visualizations
- Model performance comparisons
- Prediction vs actual plots  
- Confusion matrices
- Cluster visualizations
- Feature importance plots
- Data distribution charts

### ğŸ¤– Trained Models
- Salary predictor (regression)
- Experience level classifier
- Job market clusterer

### ğŸ“‹ Detailed Reports
- Model performance metrics
- Feature importance analysis
- Cluster characteristics
- Business recommendations

## âš™ï¸ Configuration

The project uses a centralized configuration system:

- `config/config.yaml` - Main settings
- `.env` - Environment-specific variables (database credentials, API keys)
- Command-line arguments for runtime customization

## ğŸ§ª Testing

```bash
# Run unit tests
python -m pytest tests/

# Run specific test
python -m pytest tests/test_models.py
```

## ğŸ“ˆ Next Steps

- [ ] Web interface for interactive analysis
- [ ] Real-time data pipeline integration
- [ ] Advanced feature engineering
- [ ] Deep learning models
- [ ] API for model serving
- [ ] Dashboard development

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Built with â¤ï¸ for data science and AI job market analysis** 